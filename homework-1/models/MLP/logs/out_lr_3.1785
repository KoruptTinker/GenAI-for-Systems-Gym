
------------------------------------------------------------
Sender: LSF System <lsfadmin@gpu09>
Subject: Job 1785: <sec3task5lr3> in cluster <Hazel> Exited

Job <sec3task5lr3> was submitted from host <login02> by user <bkbhayan> in cluster <Hazel> at Sat Feb 22 13:54:35 2025
Job was executed on host(s) <gpu09>, in queue <gpu>, as user <bkbhayan> in cluster <Hazel> at Sat Feb 22 13:54:59 2025
</home/bkbhayan> was used as the home directory.
</share/csc591s25/bkbhayan/GenAI-for-Systems-Gym/homework-1/models/MLP/scripts> was used as the working directory.
Started at Sat Feb 22 13:54:59 2025
Terminated at Sat Feb 22 13:54:59 2025
Results reported at Sat Feb 22 13:54:59 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -n 1
#BSUB -W 12:00
#BSUB -q gpu
#BSUB -gpu "num=1"
#BSUB -J sec3task5lr3
#BSUB -o /share/csc591s25/bkbhayan/GenAI-for-Systems-Gym/homework-1/models/MLP/logs/out_lr_3.%J
#BSUB -e /share/csc591s25/bkbhayan/GenAI-for-Systems-Gym/homework-1/models/MLP/logs/err_lr_3.%J

source ~/.bashrc
conda activate /share/$GROUP/conda_env/new_env
cd /share/$GROUP/$USER/GenAI-for-Systems-Gym/homework-1/models/MLP

python3 -m cache_replacement.policy_learning.cache_model.main \
  --experiment_base_dir=/share/$GROUP/$USER/GenAI-for-Systems-Gym/homework-1/models/MLP/experiments \
  --experiment_name=sec3task5lr3 \
  --cache_configs=cache_replacement/policy_learning/cache/configs/default.json \
  --model_bindings="loss=[\"log_likelihood\"]" \
  --model_bindings="address_embedder.max_vocab_size=5000" \
  --model_bindings="lr=0.001" \
  --train_memtrace=/share/$GROUP/traces/astar_313B_train.csv \
  --valid_memtrace=/share/$GROUP/traces/astar_313B_valid.csv

------------------------------------------------------------

Exited.


The output (if any) is above this job summary.



PS:

Read file </share/csc591s25/bkbhayan/GenAI-for-Systems-Gym/homework-1/models/MLP/logs/err_lr_3.1785> for stderr output of this job.

